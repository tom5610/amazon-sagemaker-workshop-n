{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using TensorFlow v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem\n",
    "\n",
    "To do image classification to identify objects like airplane, automobile, bird, cat, deer, dog, frog, horse, ship and trunk. We shall use Deep Learning framework TensorFlow to train a CNN model backed by [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). \n",
    "\n",
    "CIFAR is an acronym that stands for the [Canadian Institute For Advanced Research](https://cifar.ca/) and the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) was developed along with the CIFAR-100 dataset by researhers at the CIFAR instite.\n",
    "\n",
    "For [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), it consists of 60,000 32x32 pixel color pictures of objects from 10 classes, such as bird, cat and deer, etc. The class labels and their standard associated integer values are listed below:\n",
    "\n",
    "* 0: airplane\n",
    "* 1: automobile\n",
    "* 2: bird\n",
    "* 3: cat\n",
    "* 4: deer\n",
    "* 5: dog\n",
    "* 6: frog\n",
    "* 7: horse\n",
    "* 8: ship\n",
    "* 9: truck\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /root/.local/lib/python3.7/site-packages (21.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /root/.local/lib/python3.7/site-packages (3.5.1)\n",
      "Requirement already satisfied: tensorflow-datasets in /root/.local/lib/python3.7/site-packages (4.4.0)\n",
      "Requirement already satisfied: ipywidgets in /root/.local/lib/python3.7/site-packages (7.6.5)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/site-packages (4.3.0.36)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /root/.local/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (20.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/.local/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /root/.local/lib/python3.7/site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/.local/lib/python3.7/site-packages (from matplotlib) (4.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/.local/lib/python3.7/site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: termcolor in /root/.local/lib/python3.7/site-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from tensorflow-datasets) (3.10.0.0)\n",
      "Requirement already satisfied: dill in /root/.local/lib/python3.7/site-packages (from tensorflow-datasets) (0.3.4)\n",
      "Requirement already satisfied: tensorflow-metadata in /root/.local/lib/python3.7/site-packages (from tensorflow-datasets) (1.6.0)\n",
      "Requirement already satisfied: absl-py in /root/.local/lib/python3.7/site-packages (from tensorflow-datasets) (1.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from tensorflow-datasets) (1.16.0)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/site-packages (from tensorflow-datasets) (2.24.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/site-packages (from tensorflow-datasets) (5.4.0)\n",
      "Requirement already satisfied: future in /root/.local/lib/python3.7/site-packages (from tensorflow-datasets) (0.18.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow-datasets) (21.2.0)\n",
      "Requirement already satisfied: promise in /root/.local/lib/python3.7/site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /root/.local/lib/python3.7/site-packages (from tensorflow-datasets) (3.19.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (7.16.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /root/.local/lib/python3.7/site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /root/.local/lib/python3.7/site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (59.3.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi<=0.17.2,>=0.10 in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.24)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.8)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/site-packages (from importlib-resources->tensorflow-datasets) (3.4.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /root/.local/lib/python3.7/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.54.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.7/site-packages (from jedi<=0.17.2,>=0.10->ipython>=4.0.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.5.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.4.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.4)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.0)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/site-packages (from pexpect->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.10)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Installing collected packages: tqdm\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed tqdm-4.62.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip --user\n",
    "!{sys.executable} -m pip install matplotlib tensorflow-datasets ipywidgets opencv-python --user\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), info = tfds.load('cifar10', split=['train', 'test'], as_supervised=True, with_info=True, shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='cifar10',\n",
       "    full_name='cifar10/3.0.2',\n",
       "    description=\"\"\"\n",
       "    The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
       "    \"\"\",\n",
       "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
       "    data_path='/root/tensorflow_datasets/cifar10/3.0.2',\n",
       "    download_size=162.17 MiB,\n",
       "    dataset_size=132.40 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'id': Text(shape=(), dtype=tf.string),\n",
       "        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=50000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
       "        author = {Alex Krizhevsky},\n",
       "        title = {Learning multiple layers of features from tiny images},\n",
       "        institution = {},\n",
       "        year = {2009}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = info.features['label'].names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lstr ~/tensorflow_datasets/cifar10/3.0.2/cifar10-train.tfrecord-00000-of-00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l /root/tensorflow_datasets/cifar10/3.0.2/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l $filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = [32, 32]\n",
    "\n",
    "\n",
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "\n",
    "def read_tfrecord(example, labeled):\n",
    "    tfrecord_format = (\n",
    "        {\n",
    "            \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "            \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "        if labeled\n",
    "        else {\"image\": tf.io.FixedLenFeature([], tf.string),}\n",
    "    )\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example[\"image\"])\n",
    "    if labeled:\n",
    "        label = tf.cast(example[\"label\"], tf.int32)\n",
    "        return image, label\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_dataset(filenames, labeled=True):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        filenames\n",
    "    )  # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(\n",
    "        ignore_order\n",
    "    )  # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(\n",
    "        partial(read_tfrecord, labeled=labeled), num_parallel_calls=BATCH_SIZE\n",
    "    )\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n",
    "    return dataset\n",
    "\n",
    "def get_dataset(filenames, labeled=True):\n",
    "    dataset = load_dataset(filenames, labeled=labeled)\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.prefetch(buffer_size=BATCH_SIZE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/root/tensorflow_datasets/cifar10/3.0.2/cifar10-train.tfrecord-00000-of-00001\"\n",
    "dataset = get_dataset([filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(dataset))\n",
    "\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5, 5, n + 1)\n",
    "        plt.imshow(image_batch[n] / 255.0)\n",
    "        title = class_names[label_batch[n].item()]\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_batch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_batch.numpy()[1].item(), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_train, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To build the training data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(normalize_img)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To build the validation data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(normalize_img)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-01-28 22:21:38.477 tensorflow-2-3-cpu-py-ml-t3-medium-37f9e9ca00776b5a267026dff80d:376 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-01-28 22:21:38.822 tensorflow-2-3-cpu-py-ml-t3-medium-37f9e9ca00776b5a267026dff80d:376 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 159,018\n",
      "Trainable params: 159,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(len(class_names), activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "391/391 [==============================] - 19s 48ms/step - loss: 2.1198 - sparse_categorical_accuracy: 0.3371 - val_loss: 2.0464 - val_sparse_categorical_accuracy: 0.4102\n",
      "Epoch 2/6\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.0174 - sparse_categorical_accuracy: 0.4417 - val_loss: 1.9975 - val_sparse_categorical_accuracy: 0.4590\n",
      "Epoch 3/6\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.9680 - sparse_categorical_accuracy: 0.4924 - val_loss: 1.9625 - val_sparse_categorical_accuracy: 0.4968\n",
      "Epoch 4/6\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.9343 - sparse_categorical_accuracy: 0.5283 - val_loss: 1.9230 - val_sparse_categorical_accuracy: 0.5375\n",
      "Epoch 5/6\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.9114 - sparse_categorical_accuracy: 0.5503 - val_loss: 1.9220 - val_sparse_categorical_accuracy: 0.5379\n",
      "Epoch 6/6\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 1.8966 - sparse_categorical_accuracy: 0.5642 - val_loss: 1.8916 - val_sparse_categorical_accuracy: 0.5682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7385324590>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=6, validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 - 1s - loss: 1.8916 - sparse_categorical_accuracy: 0.5682\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(ds_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results: loss=1.89163; sparse_categorical_accuracy=0.56820\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "        \"Validation results: \"\n",
    "        + \"; \".join(map(\n",
    "            lambda i: f\"{model.metrics_names[i]}={scores[i]:.5f}\", range(len(model.metrics_names))\n",
    "        ))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"data/cat.png\", 1)\n",
    "\n",
    "# resize, as our model is expecting images in 32x32.\n",
    "image = cv2.resize(image, (32, 32))\n",
    "image = image / 255.0\n",
    "\n",
    "image = np.expand_dims(image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in ds_test.take(1):\n",
    "    labels = label\n",
    "    images = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2802919e-01 6.5504567e-04 7.2071500e-02 1.1517079e-02 2.9452860e-03\n",
      "  1.0040117e-03 2.4559739e-07 1.7016700e-06 6.8375224e-01 2.3688415e-05]] 8\n",
      "prediction: ship\n",
      "actual: dog\n"
     ]
    }
   ],
   "source": [
    "index = 4\n",
    "# target_image = np.expand_dims(images[index], axis = 0)\n",
    "target_image = image\n",
    "pred = model.predict(target_image)\n",
    "print(pred, np.argmax(pred))\n",
    "\n",
    "print(f\"prediction: {class_names[np.argmax(pred)]}\")\n",
    "print(f\"actual: {class_names[labels[index]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/1/assets\n"
     ]
    }
   ],
   "source": [
    "export_path = './model/1'\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install gnupg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Background processes not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d0f84eb4d4a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list &&  '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;31m# os.system() or use ip.system=ip.system_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;31m# if they really want a background process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Background processes not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;31m# we explicitly do NOT return the subprocess status code, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Background processes not supported."
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB]               \n",
      "Get:3 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.8 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2517 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]    \n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [738 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1463 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2242 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.5 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2954 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [771 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.6 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.6 kB]\n",
      "Fetched 24.1 MB in 7s (3598 kB/s)                                              \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "E: Unable to locate package tensorflow-model-server\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install tensorflow-model-server\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflow_model_server --rest_api_port=8501 --model_name=cifar10-model --model_base_path=/root/amazon-sagemaker-workshop-n/cv_byo/model > server.log 2>$1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(idx, title):\n",
    "  plt.figure()\n",
    "  plt.imshow(test_images[idx].reshape(28,28))\n",
    "  plt.axis('off')\n",
    "  plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})\n",
    "\n",
    "import random\n",
    "rando = random.randint(0,len(test_images)-1)\n",
    "show(rando, 'An Example Image: {}'.format(class_names[test_labels[rando]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "image = cv2.imread(\"data/cat.png\", 1)\n",
    "\n",
    "# resize, as our model is expecting images in 32x32.\n",
    "image = cv2.resize(image, (32, 32))\n",
    "image = image / 255.0\n",
    "\n",
    "image = np.expand_dims(image, axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "data = json.dumps({\n",
    "    \"signature_name\": \"serving_default\", \"instances\": image[:].tolist()\n",
    "})\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.228029341, 0.000655044627, 0.0720714778, 0.0115170609, 0.00294528017, 0.00100401102, 2.45596397e-07, 1.701668e-06, 0.68375212, 2.36883661e-05]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/cifar10-model:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "print(predictions)\n",
    "print(np.argmax(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training part\n",
    "%%sh\n",
    "\n",
    "python ./container/cifar10/cifar10.py --data-dir /root/data/ --model-dir ./model --train-steps 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"s3://sagemaker-ap-southeast-2-835880313890/DEMO-tensorflow-cifar10/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We will be using Keras (CNN) to train a computer vision model backed by [Intel Image Scene Classification of Multiclass](https://www.kaggle.com/puneet6060/intel-image-classification) image dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Intel Image Classification dataset\n",
    "\n",
    "Run below shell command to download and unzip the images\n",
    "```shell\n",
    "# please use the proper folder name on your local\n",
    "folder=amazon-sagemaker-workshop-n\n",
    "\n",
    "cd ~/$folder/02_bring_your_own_container/data\n",
    "\n",
    "time wget https://df4l9poikws9t.cloudfront.net/shared/sagemaker/data/intel_image_classification.zip -O ./intel_image_classification.zip\n",
    "\n",
    "time unzip intel_image_classification.zip \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intel Image Classification\n",
    "\n",
    "This notebook will do basic analysis on the image data and train a simple image classification model using regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "!{sys.executable} -m pip install seaborn tqdm\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "IMAGE_SIZE = (150, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datasets = ['./data/seg_train/seg_train', './data/seg_test/seg_test']):\n",
    "    output = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "        \n",
    "        print(f\"Loading images from {dataset}\")\n",
    "        \n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "            \n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "                \n",
    "                # get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "                \n",
    "                image_paths.append(img_path)\n",
    "                labels.append(label)\n",
    "                       \n",
    "        output.append((image_paths, labels))\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = shuffle(train_images, train_labels, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training dataset amount: {len(train_labels)}\")\n",
    "print(f\"testing dataset amount: {len(test_labels)}\")\n",
    "print(f\"image size: {IMAGE_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_, train_counts = np.unique(train_labels, return_counts = True)\n",
    "_, test_counts = np.unique(test_labels, return_counts = True)\n",
    "\n",
    "pd.DataFrame({'train':train_counts, 'test': test_counts}, index = class_names).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(\n",
    "    train_counts, \n",
    "    explode = (0, 0, 0, 0, 0, 0),\n",
    "    labels = class_names,\n",
    "    autopct = '%1.1f%%')\n",
    "    \n",
    "plt.axis('equal')\n",
    "plt.title('Proportion of each observed category - Train Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(\n",
    "    test_counts, \n",
    "    explode = (0, 0, 0, 0, 0, 0),\n",
    "    labels = class_names,\n",
    "    autopct = '%1.1f%%')\n",
    "    \n",
    "plt.axis('equal')\n",
    "plt.title('Proportion of each observed category - Test Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def get_image_array(image_path):\n",
    "    img = Image.open(image_path, 'r')\n",
    "    return np.array(img)\n",
    "\n",
    "def display_examples(class_names, image_paths, labels):\n",
    "    fig = plt.figure(figsize = (10, 10))\n",
    "    fig.suptitle('Some examples of images of the dataset', fontsize = 16)\n",
    "    \n",
    "    for i in range(20):\n",
    "        plt.subplot(4, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(get_image_array(image_paths[i]))\n",
    "        plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_examples(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation\n",
    "Image augmentation applies transforms to an image and results in additional images that the network can train on. Image data generator has many options and also allows custom preprocessing functions through the parameter of the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(99)\n",
    "\n",
    "def blur_preprocessing(img):\n",
    "    return cv2.blur(img, (5, 5))\n",
    "\n",
    "# training data generator\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale = 1.0 / 255.0, \n",
    "    validation_split = 0.0, # it's for training dataset only\n",
    "    rotation_range = 180,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    preprocessing_function = blur_preprocessing\n",
    ")\n",
    "\n",
    "# training dataset\n",
    "train_data_multi = train_data_generator.flow_from_directory(\n",
    "    directory = './data/seg_train/seg_train',\n",
    "    target_size = IMAGE_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "# testing data generator\n",
    "validation_data_generator = ImageDataGenerator(\n",
    "    rescale = 1.0 / 255.0\n",
    ")\n",
    "\n",
    "# testing dataset\n",
    "validation_data_multi = validation_data_generator.flow_from_directory(\n",
    "    directory = './data/seg_test/seg_test',\n",
    "    target_size = IMAGE_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(len(class_names), activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "history = model.fit(\n",
    "    train_data_multi, \n",
    "    batch_size = 128,\n",
    "    epochs = 5,\n",
    "    validation_data = validation_data_multi,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-2:452832661640:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
